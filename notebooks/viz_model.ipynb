{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../unet/\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "% matplotlib inline\n",
    "\n",
    "from keras_unet import build_unet, mean_iou, my_sigmoid_cross_entropy, pixelwise_weighted_cross_entropy_loss\n",
    "from keras.models import Model, load_model\n",
    "from my_utils import load_saved_data, plots\n",
    "from SegDataGenerator import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.morphology import label\n",
    "\n",
    "from SegDataGenerator import SegDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RGB = True\n",
    "USE_WEIGHTS = True\n",
    "NORMALIZE = True\n",
    "\n",
    "IMG_HEIGHT = IMG_WIDTH= 256\n",
    "IMG_CHANNELS = 3 if RGB else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_path = '../unet/models/'\n",
    "model_name = 'rgb_normalize_no_bn_weights_24'\n",
    "model_path = models_path + model_name + '.hdf5'\n",
    "\n",
    "# unet_rgb_batchnorm_24\n",
    "# unet_rgb_weights_08.hdf5\n",
    "# unet_grayscale_weights.hdf5\n",
    "custom_objects = {'mean_iou': mean_iou, \n",
    "                                   'my_sigmoid_cross_entropy': my_sigmoid_cross_entropy, \n",
    "                                   'pixelwise_weighted_cross_entropy_loss': pixelwise_weighted_cross_entropy_loss}\n",
    "model = load_model(model_path, custom_objects=custom_objects)\n",
    "\n",
    "# OLD - load from weights. Note that we need to turn off batchnorm for models that are saved like this\n",
    "# model = build_unet(0.0, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, USE_WEIGHTS)\n",
    "# model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/dataset_fixed_256x256.npz'\n",
    "X_train, Y_train, C_train, W_train, X_test = load_saved_data(data_path, image_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "if not NORMALIZE: \n",
    "    if not RGB:\n",
    "        X_train_gray = np.zeros((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "        X_test_gray = np.zeros((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "        for i in range(X_train.shape[0]):\n",
    "            X_train_gray[i,:,:,:] = rgb2gray(X_train[i,:,:,:])\n",
    "        for i in range(X_test.shape[0]):\n",
    "            X_test_gray[i,:,:,:] = rgb2gray(X_test[i,:,:,:])    \n",
    "        X_train = X_train_gray\n",
    "        X_test = X_test_gray\n",
    "\n",
    "    split = 0.8\n",
    "    X_train, Y_train = X_train[:int(X_train.shape[0]*split)], Y_train[:int(X_train.shape[0]*split)]\n",
    "    X_val, Y_val = X_train[int(X_train.shape[0]*split):], Y_train[int(X_train.shape[0]*split):]\n",
    "    \n",
    "else: \n",
    "    trainGenerator = SegDataGenerator(validation_split=0.2,\n",
    "                                  horizontal_flip=True, vertical_flip=True,\n",
    "                                  elastic_transform=True, rotation_right=True, \n",
    "                                  featurewise_center=NORMALIZE, featurewise_std_normalization=NORMALIZE)\n",
    "    trainGenerator.fit(X_train)\n",
    "    \n",
    "    batch_size = 4\n",
    "    color_mode = 'rgb' if RGB else 'grayscale'\n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH)\n",
    "    train_data = trainGenerator.flow_from_directory(data_path, subset='training', batch_size=batch_size,\n",
    "                                               class_mode='segmentation', color_mode=color_mode,\n",
    "                                               use_weights=USE_WEIGHTS, use_contour=False, label_bw=True,\n",
    "                                               target_size=target_size)\n",
    "    val_data = trainGenerator.flow_from_directory(data_path, subset='validation', batch_size=batch_size,\n",
    "                                              class_mode='segmentation', color_mode=color_mode, \n",
    "                                              use_weights=USE_WEIGHTS, use_contour=False, label_bw=True, \n",
    "                                              target_size=target_size)\n",
    "    \n",
    "    testGenerator = SegDataGenerator(featurewise_center=NORMALIZE, featurewise_std_normalization=NORMALIZE)\n",
    "    testGenerator.fit(X_train)\n",
    "    test_data = trainGenerator.flow_from_directory(data_path, subset='testing', batch_size=batch_size,\n",
    "                                               class_mode='segmentation', color_mode=color_mode,\n",
    "                                               use_weights=USE_WEIGHTS, use_contour=False, label_bw=True,\n",
    "                                               target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_data)\n",
    "plots([images[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(test_data)\n",
    "plots([images[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_train = model.predict(X_train, verbose=1)\n",
    "# preds_val = model.predict(X_val, verbose=1)\n",
    "# preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "preds_train = model.predict_generator(train_data, verbose=1)\n",
    "preds_val = model.predict_generator(val_data, verbose=1)\n",
    "preds_test = model.predict_generator(test_data, verbose=1)\n",
    "\n",
    "# Threshold predictions - TODO figure out what happens without this\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "TEST_PATH = '../data/stage1_test/'\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "# Drop garbage layer if using weights\n",
    "if USE_WEIGHTS:\n",
    "    preds_train = preds_train[:,:,:,0]\n",
    "    preds_val = preds_val[:,:,:,0]\n",
    "    preds_test = preds_test[:,:,:,0]\n",
    "    preds_train_t = preds_train_t[:,:,:,0]\n",
    "    preds_val_t = preds_val_t[:,:,:,0]\n",
    "    preds_test_t = preds_test_t[:,:,:,0]\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "sizes_test = []\n",
    "print('Getting test image sizes ...')\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    pred = preds_test[i] \n",
    "    preds_test_upsampled.append(resize(np.squeeze(pred), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t)); print(ix)\n",
    "plots([X_train[ix], \n",
    "       Y_train[ix], \n",
    "       preds_train_t[ix]], \n",
    "       titles=['image', 'label', 'output'])\n",
    "\n",
    "# Perform a sanity check on some random validation samples\n",
    "for _ in range(5):\n",
    "    ix = random.randint(0, len(preds_val_t)-1); print(ix, ix+X_train.shape[0])\n",
    "    plots([X_val[ix], \n",
    "          Y_val[ix], \n",
    "          preds_val_t[ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of difficult images in X_train\n",
    "hard_idxs = [231, 353, 415, 533, 565, 586, 611, 628, 634] \n",
    "\n",
    "imgs_to_plot = []\n",
    "for idx in hard_idxs:\n",
    "    if idx < int(X_train.shape[0]):\n",
    "        imgs_to_plot.append(X_train[idx])\n",
    "        imgs_to_plot.append(Y_train[idx])\n",
    "        imgs_to_plot.append(preds_train_t[idx])\n",
    "    else:\n",
    "        idx = idx-int(X_train.shape[0])\n",
    "        imgs_to_plot.append(X_val[idx])\n",
    "        imgs_to_plot.append(Y_val[idx])\n",
    "        imgs_to_plot.append(preds_val_t[idx])\n",
    "    \n",
    "n = len(hard_idxs)\n",
    "titles = ['input', 'label', 'output'] + ['']*(3*n-3)\n",
    "plots(imgs_to_plot, figsize=(9,n*3), rows=n, titles=titles)\n",
    "plt.savefig('output_examples/' + model_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try on test set\n",
    "ix = random.randint(0, len(preds_test_t))\n",
    "plots([X_test[ix], preds_test_t[ix] if not USE_WEIGHTS else preds_test_t[ix]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute estimate of score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Collection of methods to compute the score.\n",
    "From: https://www.kaggle.com/raoulma/nuclei-dsb-2018-tensorflow-u-net-score-0-352\n",
    "\n",
    "1. We start with a true and predicted mask, corresponding to one train image.\n",
    "\n",
    "2. The true mask is segmented into different objects. Here lies a main source \n",
    "of error. Overlapping or touching nuclei are not separated but are labeled as \n",
    "one object. This means that the target mask can contain less objects than \n",
    "those that have been originally identified by humans.\n",
    "\n",
    "3. In the same manner the predicted mask is segmented into different objects.\n",
    "\n",
    "4. We compute all intersections between the objects of the true and predicted \n",
    "masks. Starting with the largest intersection area we assign true objects to \n",
    "predicted ones, until there are no true/pred objects left that overlap. \n",
    "We then compute for each true/pred object pair their corresponding intersection \n",
    "over union (iou) ratio. \n",
    "\n",
    "5. Given some threshold t we count the object pairs that have an iou > t, which\n",
    "yields the number of true positives: tp(t). True objects that have no partner are \n",
    "counted as false positives: fp(t). Likewise, predicted objects without a counterpart\n",
    "a counted as false negatives: fn(t).\n",
    "\n",
    "6. Now, we compute the precision tp(t)/(tp(t)+fp(t)+fn(t)) for t=0.5,0.55,0.60,...,0.95\n",
    "and take the mean value as the final precision (score).\n",
    "\"\"\"\n",
    "\n",
    "def get_labeled_mask(mask, cutoff=.5, min_object_size=1.):\n",
    "    \"\"\"Object segmentation by labeling the mask.\"\"\"\n",
    "    mask = mask.reshape(mask.shape[0], mask.shape[1])\n",
    "    lab_mask = skimage.morphology.label(mask > cutoff) \n",
    "    \n",
    "    # Keep only objects that are large enough.\n",
    "    (mask_labels, mask_sizes) = np.unique(lab_mask, return_counts=True)\n",
    "    if (mask_sizes < min_object_size).any():\n",
    "        mask_labels = mask_labels[mask_sizes < min_object_size]\n",
    "        for n in mask_labels:\n",
    "            lab_mask[lab_mask == n] = 0\n",
    "        lab_mask = skimage.morphology.label(lab_mask > cutoff) \n",
    "    \n",
    "    return lab_mask  \n",
    "\n",
    "def get_iou(y_true_labeled, y_pred_labeled):\n",
    "    \"\"\"Compute non-zero intersections over unions.\"\"\"\n",
    "    # Array of different objects and occupied area.\n",
    "    (true_labels, true_areas) = np.unique(y_true_labeled, return_counts=True)\n",
    "    (pred_labels, pred_areas) = np.unique(y_pred_labeled, return_counts=True)\n",
    "\n",
    "    # Number of different labels.\n",
    "    n_true_labels = len(true_labels)\n",
    "    n_pred_labels = len(pred_labels)\n",
    "\n",
    "    # Each mask has at least one identified object.\n",
    "    if (n_true_labels > 1) and (n_pred_labels > 1):\n",
    "        \n",
    "        # Compute all intersections between the objects.\n",
    "        all_intersections = np.zeros((n_true_labels, n_pred_labels))\n",
    "        for i in range(y_true_labeled.shape[0]):\n",
    "            for j in range(y_true_labeled.shape[1]):\n",
    "                m = y_true_labeled[i,j]\n",
    "                n = y_pred_labeled[i,j]\n",
    "                all_intersections[m,n] += 1 \n",
    "\n",
    "        # Assign predicted to true background.\n",
    "        assigned = [[0,0]]\n",
    "        tmp = all_intersections.copy()\n",
    "        tmp[0,:] = -1\n",
    "        tmp[:,0] = -1\n",
    "\n",
    "        # Assign predicted to true objects if they have any overlap.\n",
    "        for i in range(1, np.min([n_true_labels, n_pred_labels])):\n",
    "            mn = list(np.unravel_index(np.argmax(tmp), (n_true_labels, n_pred_labels)))\n",
    "            if all_intersections[mn[0], mn[1]] > 0:\n",
    "                assigned.append(mn)\n",
    "            tmp[mn[0],:] = -1\n",
    "            tmp[:,mn[1]] = -1\n",
    "        assigned = np.array(assigned)\n",
    "\n",
    "        # Intersections over unions.\n",
    "        intersection = np.array([all_intersections[m,n] for m,n in assigned])\n",
    "        union = np.array([(true_areas[m] + pred_areas[n] - all_intersections[m,n]) \n",
    "                           for m,n in assigned])\n",
    "        iou = intersection / union\n",
    "\n",
    "        # Remove background.\n",
    "        iou = iou[1:]\n",
    "        assigned = assigned[1:]\n",
    "        true_labels = true_labels[1:]\n",
    "        pred_labels = pred_labels[1:]\n",
    "\n",
    "        # Labels that are not assigned.\n",
    "        true_not_assigned = np.setdiff1d(true_labels, assigned[:,0])\n",
    "        pred_not_assigned = np.setdiff1d(pred_labels, assigned[:,1])\n",
    "        \n",
    "    else:\n",
    "        # in case that no object is identified in one of the masks\n",
    "        iou = np.array([])\n",
    "        assigned = np.array([])\n",
    "        true_labels = true_labels[1:]\n",
    "        pred_labels = pred_labels[1:]\n",
    "        true_not_assigned = true_labels\n",
    "        pred_not_assigned = pred_labels\n",
    "        \n",
    "    # Returning parameters.\n",
    "    params = {'iou': iou, 'assigned': assigned, 'true_not_assigned': true_not_assigned,\n",
    "             'pred_not_assigned': pred_not_assigned, 'true_labels': true_labels,\n",
    "             'pred_labels': pred_labels}\n",
    "    return params\n",
    "\n",
    "def get_score_summary(y_true, y_pred):\n",
    "    \"\"\"Compute the score for a single sample including a detailed summary.\"\"\"\n",
    "    \n",
    "    y_true_labeled = get_labeled_mask(y_true)  \n",
    "    y_pred_labeled = get_labeled_mask(y_pred)  \n",
    "    \n",
    "    params = get_iou(y_true_labeled, y_pred_labeled)\n",
    "    iou = params['iou']\n",
    "    assigned = params['assigned']\n",
    "    true_not_assigned = params['true_not_assigned']\n",
    "    pred_not_assigned = params['pred_not_assigned']\n",
    "    true_labels = params['true_labels']\n",
    "    pred_labels = params['pred_labels']\n",
    "    n_true_labels = len(true_labels)\n",
    "    n_pred_labels = len(pred_labels)\n",
    "\n",
    "    summary = []\n",
    "    for i,threshold in enumerate(np.arange(0.5, 1.0, 0.05)):\n",
    "        tp = np.sum(iou > threshold)\n",
    "        fn = n_true_labels - tp\n",
    "        fp = n_pred_labels - tp\n",
    "        if (tp+fp+fn)>0: \n",
    "            prec = tp/(tp+fp+fn)\n",
    "        else: \n",
    "            prec = 0\n",
    "        summary.append([threshold, prec, tp, fp, fn])\n",
    "\n",
    "    summary = np.array(summary)\n",
    "    score = np.mean(summary[:,1]) # Final score.\n",
    "    params_dict = {'summary': summary, 'iou': iou, 'assigned': assigned, \n",
    "                   'true_not_assigned': true_not_assigned, \n",
    "                   'pred_not_assigned': pred_not_assigned, 'true_labels': true_labels,\n",
    "                   'pred_labels': pred_labels, 'y_true_labeled': y_true_labeled,\n",
    "                   'y_pred_labeled': y_pred_labeled}\n",
    "    \n",
    "    return score, params_dict\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    \"\"\"Compute the score for a batch of samples.\"\"\"\n",
    "    scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        score,_ = get_score_summary(y_true[i], y_pred[i])\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "def imshow_args(x):\n",
    "    \"\"\"Matplotlib imshow arguments for plotting.\"\"\"\n",
    "    if len(x.shape)==2: return x, cm.gray\n",
    "    if x.shape[2]==1: return x[:,:,0], cm.gray\n",
    "    return x, None\n",
    "\n",
    "def plot_score_summary(y_true, y_pred):\n",
    "    \"\"\"Plot score summary for a single sample.\"\"\"\n",
    "    # Compute score and assign parameters.\n",
    "    score, params_dict = get_score_summary(y_true, y_pred)\n",
    "    \n",
    "    assigned = params_dict['assigned']\n",
    "    true_not_assigned = params_dict['true_not_assigned']\n",
    "    pred_not_assigned = params_dict['pred_not_assigned']\n",
    "    true_labels = params_dict['true_labels']\n",
    "    pred_labels = params_dict['pred_labels']\n",
    "    y_true_labeled = params_dict['y_true_labeled']\n",
    "    y_pred_labeled = params_dict['y_pred_labeled']\n",
    "    summary = params_dict['summary']\n",
    "\n",
    "    n_assigned = len(assigned)\n",
    "    n_true_not_assigned = len(true_not_assigned)\n",
    "    n_pred_not_assigned = len(pred_not_assigned)\n",
    "    n_true_labels = len(true_labels)\n",
    "    n_pred_labels = len(pred_labels)\n",
    "\n",
    "    # Summary dataframe.\n",
    "    summary_df = pd.DataFrame(summary,columns=['threshold','precision','tp','fp','fn'])\n",
    "    print('Final score:', score)\n",
    "    print(summary_df)\n",
    "\n",
    "    # Plots.\n",
    "    fig, axs = plt.subplots(2,3,figsize=(20,13))\n",
    "\n",
    "    # True mask with true objects.\n",
    "    img = y_true\n",
    "    axs[0,0].imshow(img, cmap=cm.gray)\n",
    "    axs[0,0].set_title('{}.) true mask: {} true objects'.format(n,'?')) #3\n",
    "    \n",
    "    # True mask with identified objects.\n",
    "    #img = np.zeros(y_true.shape)\n",
    "    #img[y_true_labeled > 0.5] = 255\n",
    "    img, img_type = imshow_args(y_true_labeled)\n",
    "    axs[0,1].imshow(img, img_type)\n",
    "    axs[0,1].set_title('{}.) true mask: {} objects identified'.format(n, n_true_labels))\n",
    "    \n",
    "    # Predicted mask with identified objects.\n",
    "    #img = np.zeros(y_true.shape)\n",
    "    #img[y_pred_labeled > 0.5] = 255\n",
    "    img, img_type = imshow_args(y_pred_labeled)\n",
    "    axs[0,2].imshow(img, img_type)\n",
    "    axs[0,2].set_title('{}.) predicted mask: {} objects identified'.format(\n",
    "        n, n_pred_labels))\n",
    "\n",
    "    # Prediction overlap with true mask.\n",
    "    img = np.zeros(y_true.shape)\n",
    "    img[y_true > 0.5] = 100\n",
    "    for i,j in assigned: img[(y_true_labeled == i) & (y_pred_labeled == j)] = 255\n",
    "    axs[1,0].set_title('{}.) {} pred. overlaps (white) with true objects (gray)'.format(\n",
    "        n,len(assigned)))\n",
    "    axs[1,0].imshow(img, cmap='gray', norm=None)\n",
    "\n",
    "    # Intersection over union.\n",
    "    img = np.zeros(y_true.shape)\n",
    "    img[(y_pred_labeled > 0) & (y_pred_labeled < 100)] = 100\n",
    "    img[(y_true_labeled > 0) & (y_true_labeled < 100)] = 100\n",
    "    for i,j in assigned: img[(y_true_labeled == i) & (y_pred_labeled == j)] = 255\n",
    "    axs[1,1].set_title('{}.) {} intersections (white) over unions (gray)'.format(\n",
    "        n, n_assigned))\n",
    "    axs[1,1].imshow(img, cmap='gray');\n",
    "\n",
    "    # False positives and false negatives.\n",
    "    img = np.zeros(y_true.shape)\n",
    "    for i in pred_not_assigned: img[(y_pred_labeled == i)] = 255\n",
    "    for i in true_not_assigned: img[(y_true_labeled == i)] = 100\n",
    "    axs[1,2].set_title('{}.) no threshold: {} fp (white), {} fn (gray)'.format(\n",
    "        n, n_pred_not_assigned, n_true_not_assigned))\n",
    "    axs[1,2].imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import skimage.morphology\n",
    "import matplotlib.cm as cm        \n",
    "\n",
    "# Check the score metric for one sample. The predicted mask is simulated\n",
    "# and can be modified in order to check the correct implementation of\n",
    "# the score metric.\n",
    "idx = np.random.randint(len(X_train)*0.1) + int(len(X_train)*0.9)\n",
    "print(idx)\n",
    "true_mask = Y_train[idx,:,:,0].copy()\n",
    "lab_true_mask = get_labeled_mask(true_mask)\n",
    "idx_val = idx-int(len(X_train)*0.9)\n",
    "pred_mask = (preds_val_t[idx_val] if not USE_WEIGHTS else preds_val_t[idx_val][:,:,0]).squeeze()\n",
    "plot_score_summary(true_mask, pred_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# evaluate score on validation set\n",
    "scores = []\n",
    "for idx in tqdm(range(int(len(X_train)*0.1))):\n",
    "    idx_train = idx + int(len(X_train)*0.9)\n",
    "    true_mask = Y_train[idx_train,:,:,0].copy()\n",
    "    lab_true_mask = get_labeled_mask(true_mask)\n",
    "    pred_mask = (preds_val_t[idx] if not USE_WEIGHTS else preds_val_t[idx][:,:,0]).squeeze()\n",
    "    score, _ = get_score_summary(true_mask, pred_mask)\n",
    "    scores.append(score)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in tqdm(enumerate(test_ids)):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
